## 统计
1.bitmap,准确统计数字是否存在，所需空间较大
2.hyperloglog 不太精准的去重计数方案。在一系列随机数中，根据末尾最大连续0的个数k估算整体数据规模N和2^k成正比。默认有2^14个桶，每个桶存放末尾最大连续0的个数。对每个字符串计算hash值，对2^14取模(保留低14位)，更新对应桶。最后取桶的调和平均，对2取指数。
3.布隆过滤器，不太精准的去重方案。使用一个bitmap用于记录，k个hash函数对key进行hash，对bitmap长度取模算出整数索引值，每个hash函数得到一个位置。把bitmap这若干位置1完成add操作。查询key是否存在时，看bitmap中由k个hash函数对key计算出的若干位是否全部为1。只要有1个0，key必然不存在。如果全部为1，极大概率存在。
## 持久化
1、RDB快照 一次性的全量备份，将内存数据二进制序列化存入磁盘。RDB利用copy on write机制实现快照，创建子进程将内存数据写入磁盘。父进程修改数据子进程不可见，因此称为快照。
2.AOF日志连续增量备份日志，记录修改内存数据的指令。定期AOF重写，给AOF日志瘦身。程序对AOF日志执行写操作事实上是写到内核为文件描述符分配的一个缓存中，内核会异步将数据写到磁盘。为防止突然宕机造成日志丢失，Redis会调用fsync将数据同步到磁盘（磁盘I/O影响性能，所以定期执行而不是每条指令都执行）。日志重写是开辟子进程遍历内存，根据当前数据库状态生成一系列redis指令，序列化到新的AOF文件中，再把操作期间的增量AOF日志追加到尾部，生成新的AOF文件来代替旧的。
3、混合持久化
Redis重启恢复内存状态时，使用rdb会丢失大量数据，使用AOF日志重放速度又太慢。使用rdb快照和AOF增量日志结合方式来混和持久化。AOF日志只保存了rdb持久化期间的增量日志。
## 数据结构
1、字符串：SDS字符串（加入len字段标记长度/动态开辟空间还有预分配策略，free记录剩余空间/惰性空间释放，释放入free中），底层存放c风格字符串。
2、hash表
开链法：数组加链表
哈希表包括：/哈希表大小（数组的长度，总是2的幂次）/哈希表大小掩码（为size-1，由于数组长度是2的幂次，取余可以用掩码&计算代替）

哈希表节点：保存键值对，同时持有指针指向同一个slot中的下节点。发生键值冲突时，新的表节点总是插入到相应slot的链表的头部。考虑数据库中最新被插入的数据更可能被取用，所以插入到头部。

怎么rehash，rehash的时候是不是一定要全部复制？
渐进式rehash
持有两个hash表ht0和ht1。
1.为ht1分配足够大小的空间/2.将ht0上的所有键值对rehash到ht1上，重新计算键的哈希值和索引，将键值对放到ht1对应的位置上/3迁移完释放ht0，将ht1设置为ht0，并新建空白hash表放到ht1。
在rehash期间同时使用ht0和ht1两个hash表完成查找操作。在每次执行写命令hset/hdel时先进行一次搬迁操作，如果是添加键值对添加在ht1上。
什么时候触发rehash？
负载因子：hash.used(已使用节点数)/hash.size（hash表大小）
负载因子大于限制会触发rehash，如果没有rdb快照，门限值为1，否则为5。Rdb快照时，对内存数据的修改需要拷贝到父进程中修改，然后复制回去（copy on write）需要更多内存写入，应该尽量避免rehash。
3、跳表
zskiplist 包含头指针/尾指针/跳表的长度（不包含头节点）/最大层数（目前跳表节点中层数最大的节点层数）
跳表节点：1.存放若干层结构的level数组（层数根据幂次定律，随机生成一个介于1到32/64之间的数作为数组的长度）2.后退指针（指向跳表中前一个跳表节点，后退只能退至前一个节点）3.double存放分值4.指针存放成员对象
每一个level结构包含一个前进指针和和跨度（uint值） 前进指针指向同一层的下一个节点，跨度记录这两个节点之间的距离。跨度用来计算节点在链表中的排位。
跳表比红黑树的好处在于实现结构简单，同时更适合进行范围操作。如取第n到n+m的值，红黑树需要在两个对应节点之间进行中序遍历，而跳表可以直接遍历最底层的链表。

zset 由hash表和一个跳表组成。hash表用于常规时间获取给定元素的分数。跳表按分值大小，保存所有集合元素，用于提供范围型操作接口。两种数据结构通过指针共享相同元素的成员和分值，没有重复和内存浪费。

4、压缩列表ziplist：
列表包含少量列表项，每个列表项存储小整数值或短字符串。
一块连续空间，分为对象头和一系列的entry，每个entry相当于是list的一个元素。entry中preLen字段记录前一个entry长度(用于倒序遍历)，然后是encoding字段表示entry的编码类型，最后是byte[]。preLen是可变长整数，长度小于254(0xFE)时为1B，大于时改用5B表示。因此，当修改一个entry的内容时，需要修改后一个entry的preLen字段，如果preLen字段由1B变为了5B，则还需要修改再下一个entry，从而导致级联更新。

5、快速列表quicklist就是多个压缩列表的链表形式，默认其中一个压缩列表8k。
6、升级版压缩列表listpack和ziplist相比，listpack将entry的长度length存在了本entry的结构中，因此不存在了级联更新。
7、基数树radixtree
redis实现的基数树和字典树Trietree相比，每一层可以不是一个字符(传统Trie树)而是一个字符串，从而避免深度过大。

## 空间释放
过期策略
redis将设置了过期时间的键放入expires字典(键指向键空间中键对象，值为超时时间戳)
检查一个键是否过期：
1、检查是否在expires中，如果在得到过期时间戳
2、当前unix时间戳与过期时间戳比较
定时删除：定时任务执行对键的删除操作，占用太多cpu
定期删除：过期字典中，每秒扫描十次，每次使用贪心策略扫描一部分。
惰性删除：在从键空间中获取键时检查键是否过期，如果过期删除。占用太多内存。
redis使用定期删除和惰性删除结合。从节点不会主动删除key，主节点在key过期被删除时会给从节点的AOF文件增加对应的del指令。因此应当给key的过期时间加上随机扰动，避免大量key同时过期。

内存回收：
引用计数，计数存放在redis object得一个字段中，refcount。使用引用计数，让有相同值的元素共享一份实体
空转时长，lru字段，每个key有额外24bit字段，以秒为单位存储了对象新建或者更新时的unix time时间戳。
内存超限：Redis中可以配置maxmemory指定最大内存使用量。当超限时可以使用如下策略：
在Redis当中，有生存期的key被称为volatile。
noeviction(默认)：不响应写请求(可以del)，可响应读请求。
volatile-lru：尝试淘汰设置了过期时间的key，lru的key淘汰。
volatile-ttl：类似上，淘汰ttl最小的。
all-keys-lru
all-keys-random
volatile和all-keys规定了是对已设置过期时间的数据集淘汰数据还是从全部数据集淘汰数据，后面的lru、ttl以及random是三种不同的淘汰策略，再加上一种no-eviction永不回收的策略。
近似LRU算法：
维护一个待淘汰候选key的pool，里面默认有16个key，按照空闲时间排好序。更新时从Redis键空间随机选择N个key，分别计算它们的空闲时间idle，key只会在pool不满或者空闲时间大于pool里最小的时，才会进入pool，然后从pool中选择空闲时间最大的key淘汰掉。

过期时间可以通过使用DEL命令来删除整个key来移除，或者被SET和GETSET命令覆盖原来的数据。对一个已经带有过期时间的key执行EXPIRE命令，新指定的过期时间会取代旧的过期时间。
EXPIRE和TTL命令搭配使用，TTL可以查看key的当前生存时间。

管道pipeline：
一次性发送多条指令，服务器返回多条指令的结果。
写->读 + 写->读  = 写写 -> 读读

事务：
redis事务对外部表现原子性的，在事务中的所有命令都将会被串行化的顺序执行，在单线程执行事务时不会执行(响应)其他客户端的请求，从而保证了事物中的所有命令被原子的执行。

pipeline和事务的相同和区别就是，他们都是多发一答。但是pipeline中的命令一个一个发过去了，server就会执行，中间还会穿插执行其他连接上command；事务会缓存接受的指令，直到事务需要的命令都拿到了，然后一次性执行，期间不会响应其他连接上的command。


集群：
C:consistent A：availability P：partition tolerence
当网络分区发生时，一致性和可用性难两全。
redis主从间异步同步，不满足一致性要求。主从网络断开后，主节点依旧可以正常对外提供修改服务，满足可用性。但redis保证最终一致性。
增量同步：主节点将指令流记录记载本地内存buffer中，然后异步将指令同步到从节点。从节点一边执行指令流，一边反馈同步进度。
快照同步：全量同步。将内存数据写入磁盘文件再将文件内容发送到从节点。

cluster：
redis将key的空间分成2^14个槽位，每个key计算CRC16对2^14取模来确定key在哪个slot中。每个redis服务实例相互连接，每个节点负责一部分槽位，各自拥有一份slot-node映射表，不做代理转发工作，如果请求的key所在的slot不归自己处理会返回重定向，由客户端自己重新请求。集群的可用性实际是通过每个master-slave结构来保证的，如果负责一片slot的master和slave都挂了，那redis就不再提供服务。

* 重定向
MOVED
当请求给某个node的key不归自己处理时，会给客户端返回MOVED错误，并将slot归属的node的IP:Port返回给客户端，客户端自己重新请求。一般客户端会做缓存和更新。原则上客户端不需要知道所有的slot-node映射表就可以工作，但是为了效率，客户端也可以请求(Cluster Nodes / Cluster Slots)获得整个映射关系，比如首次连接时。

ASK
由于node间的slot允许存在迁移，迁移需要将一个node中slot中的key转移到另一个node中。在迁移过程中，slot会处于中间态，一部分在旧的中，一部分在新的中，每迁移一个key就会在旧的中删去。ASK的情况是，node收到key发现其slot处于迁移状态，查询发现没有这个key，但是它不能断定迁入的node中是否存在，因此需要发送ASK命令，让客户端取另一个node试一试；之后客户端先给新node发送ASKING命令，强制接下来的一个命令可以查询正在迁入的slot；然后客户端发送正常请求，并且不会更新映射关系。区别在于，MOVED的语义是，客户端需要更新映射，认为此后该slot都对应新的node。而ASK不更新映射，因为此时的slot分布在两个node中，应当有措施保证对于每一个请求能访问到这两个node。


1、存储方式 Memecache把数据全部存在内存之中，断电后会挂掉，数据不能超过内存大小。 Redis持久化硬盘上，这样能保证数据的持久性(RDB/AOF)。
2、数据支持类型 Memcache对数据类型支持相对简单，所有的值均是简单的字符串。 Redis有复杂的数据类型，支持string，list，set，sorted set，hash。
3、使用底层模型不同memcached是多线程，非阻塞IO复用的网络模型，分为监听主线程和worker子线程，监听线程监听网络连接，接受请求后，将连接描述字pipe传递给worker线程，进行读写IO，网络层使用libevent封装的事件库，多线程模型可以发挥多核作用，但是引入了cache coherency和锁的问题。
redis使用单线程的IO复用模型，自己封装了一个简单的事件处理框架，主要实现了epoll, kqueue和select，对于单纯只有IO操作来说，单线程可以将速度优势发挥到最大，但是redis也提供了一些简单的计算功能，比如排序、聚合等，对于这些操作，单线程模型施加会严重影响整体吞吐量，CPU计算过程中，整个IO调度都是被阻塞的。
4、Memcached本身并不支持分布式，因此只能在客户端通过像一致性哈希这样的分布式算法来实现Memcached的分布式存储。Redis Cluster是一个实现了分布式且允许单点故障的Redis高级版本。在Redis Cluster中，每个Master节点都会有对应的两个用于冗余的Slave节点。这样在整个集群中，任意两个节点的宕机都不会导致数据的不可用。当Master节点退出后，集群会自动选择一个Slave节点成为新的Master节点。

关于并发
Redis为单进程单线程模式，采用队列模式将并发访问变为串行访问。Redis本身没有锁的概念，Redis对于多个客户端连接并不存在竞争。客户端对Redis进行并发访问时会发生连接超时、阻塞的问题。
客户端角度，为保证每个客户端间正常有序与Redis进行通信，对连接进行池化。

WATCH mykey    //监控键值对
val = GET mykey
val = val + 1
MULTI           // 开启事务，后续命令入队列（管道）
SET mykey $val
EXEC           //执行事务，首先比较监控键值对，如果不同回滚，否则执行命令，提交事务 成功返回OK，失败返回nil
乐观锁+事务
新代码在获取mykey的值之前先通过WATCH命令监控了该键，此后又将set命令包围在事务中，这样就可以有效的保证每个连接在执行EXEC之前，如果当前连接获取的mykey的值被其它连接的客户端修改，那么当前连接的EXEC命令将执行失败。这样调用者在判断返回值后就可以获悉val是否被重新设置成功。

set nx(not exist) ex(超时时间)
set-nx-ex，成功了获得锁进行操作，操作完删掉这个值。set-nx-ex失败了，等待一段时间再次尝试。主要问题是超时时间设置多久，和等待多久重试的问题。超时短了，获得锁的线程还没完成操作，其他线程就能拿到锁。其他线程等多久进行重试也是个麻烦。

如何避免并发访问下对更新的覆盖：首先看要写入的数据源是否实现了并发控制，比如数据库，使用select...for update扩大锁范围，或者使用类似乐观锁的方式保证业务逻辑上的并发控制。如果写入的数据源没有实现并发控制，客户端可以使用分布式锁，进行同步。此外可以视情况在客户端和数据源中架设一层具有并发控制的中间代理层，比如MQ等。


Redis集群模式有redis-proxy、master、replica、HA等几个角色。在读写分离实例中，新增只读的replica角色来承担读流量，replica作为热备不提供服务，架构上保持对现有集群规格的兼容性。redis-proxy按权重将读写请求转发到master或者某个只读的replica上；HA负责监控DB节点的健康状态，异常时发起主从切换或重搭只读replica，并更新路由。 Redis主从异步复制，从只读的replica中可能读到旧的数据，使用读写分离需要业务可以容忍一定程度的数据不一致。