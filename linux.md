死锁：
1、互斥条件
2、不可抢占条件
3、占有且申请条件
4、循环等待条件

死锁避免：银行家算法：基本思想是分配资源之前，判断分配后系统状态是否是安全的；若是，才分配。并非所有的不安全状态都是死锁，但是处于不安全状态很可能产生死锁
找到一条安全执行序列：
系统试分配资源后，算法从现有进程列表寻找出一个可执行的进程进行执行，执行完 成后回收进程占用资源；进而寻找下一个可执行进程。当进程需求量大于系统可分配量时，进程无法执行。当所有进程均可执行，则产生一个安全执行序列，系统资源分配成功。找不到一条安全执行序列时，执行失败。


性能分析命令：
ps（process status）
进程监控 top

磁盘：
df:以磁盘分区为单位查看文件系统，显示文件系统的磁盘使用情况。
du: disk usage 显示磁盘空间使用情况

/proc 用户可以通过它查看系统硬件及当前运行的进程信息.
cat 
/proc/loadavg      前三列分别保存最近1分钟，5分钟，及15分钟的平均负载。 系统平均负载被定义为在特定时间间隔内运行队列中的平均进程数
/proc/meminfo    当前内存使用信息
/proc/diskstats    磁盘I/O统计信息列表
/proc/filesystems  支持的文件系统
/proc/cpuinfo      CPU的详细信息
/proc/version     当前运行的内核版本号等信息


网络分析命令：
Ping：检查网络连通性和时延 ping 域名/ip地址
Tcpdump：抓包，分析网络中数据包的头部

Netstat：显示与IP、TCP、UDP、 ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接状况。
现在使用ss（socket statistics）命令来代替netstat。当socket连接数非常多的情况下ss的速度更快。

lsof(list open file)是一个列出当前系统打开文件的工具。

free  -b –k –m –g 单位
buffers: 主要缓存dentry和inode等元数据
cached：page cache页缓存

traceroute ip/host         用于检查数据报的路由

gdb 还可以分析coredump文件
gdb l(list)查看源代码
r(run)运行到结束或者断点
b(break) 行数  break filename:行数 设置断点
info breakpoints 显示断点信息
n(next) 单步执行
s(step into) 单步步入
c(continue) 运行到下一个断点
print 查看变量值 whatis 查看变量类型
q 退出
bt查看堆栈列表，显示所有的函数调用栈帧的信息，每个帧一行
bt full栈中所有帧的完全信息：函数参数，本地变量
frame n 
f addr 选择帧
up n在栈中向上移动n个帧。即向着最外层移动n个帧。
down n
调试正在运行的程序：
ps aux|grep ### ps查看正在运行程序的pid
gdb attach pid 
gdb -p pid
detach 断开连接

info threads 查看所有线程状态
thread [tid] 进入某个线程
行首的星号标识了当前活动的线程

代码如何做调试的？：日志打印，根据日志信息定位错误
 
strace 跟踪系统调用 跟踪信号传递 -c 统计系统调用 -t 统计每个系统调用所化时间 -p pid 追踪进程

内存检查工具 valgrind：
memcheck内存检查器

Linux 程序内存空间/进程用户空间
低地址： 1.代码段
        2.初始化数据段 静态分配内存 静态存储区 已初始化的全局/静态变量 常量
        3.未初始化数据段，bss段（block started by symbol）未初始化的全局和静态变量
        4.堆
        5.栈/  局部变量 保存/恢复现场
高地址： 6.命令行参数和环境变量

栈的存取速度比堆要快，不容易产生内存碎片。栈的LIFO的存储方式，特别适用于处理执行逻辑。
存在栈中的数据大小与生存期是确定的，缺乏灵活性。栈没有办法动态增长。

不同的线程执行逻辑有所不同，因此需要一个独立的线程栈。而堆则是所有线程共享的。栈作为运行单位，存储当前线程（或程序）相关信息的。包括局部变量、程序运行状态、方法返回值等等；而堆只负责存储对象信息。
第一，从软件设计的角度看，栈代表了处理逻辑，而堆代表了数据。这样分开，使得处理逻辑更为清晰。
第二，堆与栈的分离，使得堆中的内容可以被多个栈共享（也可以理解为多个线程访问同一个对象）。这种共享的收益是很多的。一方面这种共享提供了一种有效的数据交互方式(如：共享内存)，另一方面，堆中的共享常量和缓存可以被所有栈访问，节省了空间。
第三，栈因为运行时的需要，比如保存系统运行的上下文，需要进行地址段的划分。由于栈只能单向增长，因此就会限制住栈存储内容的能力。而堆不同，堆中的对象是可以根据需要动态增长的，因此栈和堆的拆分，使得动态增长成为可能，相应栈中只需记录堆中的一个地址即可。
面向对象时：堆中存的是对象。栈中存的是基本数据类型和堆中对象的指针。指针是个固定大小4byte或8byte。

Linux 一个进程的栈：用户栈 内核栈 中断栈

从用户态进入内核态的方法：系统调用、软中断和硬件中断、异常

进程/线程
1.单线程的进程只能使用一个处理器，好处是当它发生异常或进入忙等待时仍有其他处理器可用，是一种限制程序的cpu占用率的方法，坏处是如果它独占一台机器浪费了其他处理器的计算资源，多线程主要价值在发挥多核处理器价值。
2.线程间共享地址空间，独立的线程栈但是共享堆空间。当内存中有全局状态，即线程间需要共享数据（共享的数据会修改时）时考虑单进程多线程。如果是静态常量等只读的共享数据可以使用单线程多进程+共享内存。进程的状态同步更为复杂，如果一个进程在临界区crash会导致其他进程死锁。
3.进程创建需要分配独立的内存空间和大量的相关资源，进程创建销毁的开销远大于线程创建销毁的开销，要考虑任务的具体需求。如果是任务耗时短，任务产生频繁就使用多线程，甚至线程池来降低开销。
4.程序中如果调用了fork创建进程函数，就使用单线程模型避免错误。
5、主要性能指标是latency不是throughput时。单进程多线程与多进程单线程相比理论上绝对性能相同，但是多线程可以提高平均响应性能。比如100个任务，8处理器机器，使用8个进程分别处理不同任务和单进程8个线程顺序处理100个任务的总时间相同，但是单进程多线程可以更早的拿到完成前7个任务。多线程可以让I/O和cpu计算相互重叠，降低latency，比如异步写日志等。

##　进程间通信
1、管道：半双工/用于亲属进程之间/pipe被socketpair取代，socketpair是全双工的(2个fd)pipe是半双工的。
2、有名管道：FIFO可以在无关进程间通信/作为特殊设备文件存在于文件系统中
3、消息队列：消息的链表，存放在内核中/消息队列面向记录，消息具有特定格式和特定优先级/消息队列独立于发送与接收进程。进程终止时，消息队列及内容不会被删除
4、信号量：是一个计数器，用于进程间同步/若要传递数据可结合共享内存/信号量基于系统PV操作，程序对信号量的操作是原子操作。
5、共享内存：多个进程共享同一块存储区/最快的IPC/需要进程间同步，常与信号量结合使用
6、套接字 与其它通信机制不同的是，它可用于不同机器间的进程通信。


* 共享内存：  
mmap共享映射  mmap/munmap
System v的共享内存 shmget/shmat/shmdt&shmctl
POSIX共享内存
常见的是前面两种
POSIX： 共享内存对象(fd = shm_open(),最主要的操作也是默认的操作就是在/dev/shm/下面，建立一个文件，然后使用mmap)(创建了一个打开文件描述指向一个共享内存对象，和一个文件描述符指向这个打开文件描述。其他函数通过文件描述符获取这个共享内存对象。)

System V 
Shm共享内存，不同进程之间共享的内存安排在同一段物理内存中(shmget创建，用key_t来唯一标识共享内存，shmat建立进程虚拟地址空间到共享内存的映射,shmdt用于将共享内存从当前进程中分离，shmctl用于删除这个共享内存)。进程通过虚拟地址找到用户级页表，然后通过用户级页表映射到物理内存相同的一块内存区域，使用这块区域实现进程间通信。
      

mmap是多个进程虚拟地址空间映射到同一文件磁盘地址。相比shm而言，mmap的读写速度会慢(脏页定期写回磁盘)，但是使用磁盘的存储量会大于内存。(磁盘也可以持久化吧？)
mmap 用于共享内存的两种方法：
1.	使用普通文件提供内存映射 2.父子进程间通过特殊文件提供匿名内存映射。
(方法1：每个进程都是fd=open(filename,…)打开同一个文件，然后调用mmap映射到自己进程虚拟地址空间///方法2：父进程mmap使用MAP_ANONYMOUS/MAP_ANON参数，得到返回的映射空间的起始地址，然后调用fork创建子进程，子进程继承映射后的虚拟地址空间) 
Nginx使用了MAP_ANON|MAP_SHARED 参数，此时mmap和shmget方法几乎完全相同。

* mmap:
内存映射方法，即将一个文件映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中的一段虚拟地址的——对映关系。实现映射关系后，进程可以采用指针来读写这一段内存，系统自动写脏页到对应的文件磁盘上，即完成对文件的读写而不必调用write/read等系统调用函数。内核空间对这段区域的修改也直接反映在用户空间，实现不同进程间的文件共享。
 
* mmap 步骤：
1、2：调用do_mmap() 见下面do_mmap();
do_mmap():
1、将一个新的虚拟地址区间加入到进程的地址空间中，无论是扩展已有的VMA还是创建新的VMA。如果创建新的VMA，添加到地址空间的虚拟内存区域的链表和红黑树中，返回新分配区间的初始地址。(文件映射/匿名 映射)
2、文件映射时，调用驱动的mmap。通过文件的inode定位到文件磁盘物理地址，建立页表，实现用户空间的VMA和驱动空间物理地址的映射关系。但是，这片虚拟地址没有任何数据关联到内存中。
3.进程对这片映射空间访问，引发缺页异常，实现文件内容到物理内存的拷贝。进程读或写这一段映射地址时，查询页表发现只建立了地址映射，页面不在物理页面上，引发缺页异常。内核调页，进程对这片内存进行读写。如果写操作改变了内容，一段时间后系统会将脏页自动写回硬盘，也可以使用mysnc()来强制同步。

mmap和常规文件操作的区别：
常规文件操作为了提高读写效率和保护磁盘使用了页缓存机制。读文件时需要将文件页拷贝到页缓存中，页缓存在内核空间不能被用户进程寻址，所以还要将页缓存中的数据页再次拷贝到内存中对应的用户空间中。写也是一样，写入用户空间buffer，拷贝入内核空间buffer，再异步写回磁盘，也是两次数据拷贝。使用mmap操作文件时，访问数据发现缺页异常，可以通过已建立好的映射关系，磁盘数据直接拷贝入用户空间中。
优点：1、减少数据拷贝次数2、内存读写代替I/O操作，提高文件操作的效率/3、实现了用户空间和内核空间高效交互方式/4、提供了共享内存相互通信的方式
细节：映射区域必须是物理页大小的整数倍。（32位系统时4k字节，映射区>=文件，读写超出映射区的部分会报错误，读写超出文件大小但不超过映射区大小部分不会出错，只是不会写回磁盘）

* 消息队列
使用链表实现的消息队列，新的消息总是放在队列的末尾，接收的时候并不总是从头来接收，可以从中间来接收。
Linux用宏MSGMAX和MSGMNB来限制一条消息的最大长度和一个队列的最大长度
msgget 创建和访问一个消息队列/ 程序提供键key命名某个消息队列，返回这个消息队列的标识符。
msgsnd 把消息添加到消息队列中 msgflg == IPC_NOWAIT 将不会阻塞
msgrcv 从消息队列中获取消息
msgctl 用来设置消息队列的属性和删除消息队列。
消息结构体 包含一个long int的消息类型字段和一个缓冲区
msgsend 发送信息时可以设置信息类型。
msgrcv 接收时可以设置接收信息类型，如果为0就接收队列中的第一个。

* 信号量：
SYSTEM V信号量 常用于进程间同步
semget 创建nsems个信号量
semop 用于改变信号量的值 sembuf(sem_num为要操作的信号量下标，sem_op为p操作+1,或v操作-1)
semctl 用于设置信号量初始值或删除信号量等控制信息。

POSIX 信号量：Nginx 使用的
sem_init/sem_destroy/sem_wait/sem_post 接口
可以用于进程间同步或者线程间同步 sem_init(sem_t *sem,int pshared,uint value) pshared 用于指定是在线程间还是进程间同步

System V的信号量是信号量集，可以包括多个信号灯，每个操作可以同时操作多个信号灯。posix是单个信号灯。Posix信号量是基于内存的，即信号量值是放在共享内存中的。System V需要陷入内核，执行系统调用，开销更大。

* ipcs命令
ipcs命令用于报告系统的消息队列、信号量、共享内存等
ipcs –a 用于列出本用户所有相关ipcs参数
ipcs –q 用于列出进程中的消息队列
ipcs –s 用于列出所有信号量
ipcs –m 用于列出所有共享内存信息         
ipcs –l 列出系统限额
ipcs –u 用于列出当前使用情况

### Linux进程地址空间（32位）
Linux使用虚拟内存管理技术，每个进程有独立的地址空间，该空间是大小为4G的线性虚拟地址空间。这4G空间被分为内核地址空间和用户地址空间。用户空间从0-3G(逻辑地址从0开始，为相对值)，内核空间占据3G到4G。用户进程除非系统调用、中断无法访问内核空间(用户空间3GB独立，内核空间所有进程共享)。(从用户态到内核态，cpu需要切换堆栈，进程用户栈切换到内核栈，(处理器信息/栈信息/寄存器信息))
内核使用内存描述符结构体mm_struct表示进程的地址空间。(mm_users记录正在使用该地址的进程数目/mm_count记录mm_struct的引用计数，mmap和mm_rb都是用来描述地址空间中的全部内存区域vm_area_struct,前者以有序链表形式存放，后者以红黑树形式存放，二者包含完全相同的vm_area_struct结构体。有序链表用于遍历及范围操作，而红黑树适用于搜索指定元素，二者结合也叫线索树)。task_struct的mm域存放进程地址空间的内存描述符结构体mm_struct。切换进程时，进程mm域指向的地址空间被装载到内存，进程描述符中的active_mm被更新，指向新的地址空间。(内核线程没有进程地址空间，mm域为空。内核线程直接使用前一个线程的内存描述符，内核线程的active_mm域指向前一个进程的内存描述符，所以它可以使用前一个线程的页表)。

进程的虚拟地址空间有多个虚拟内存区域。虚拟内存区域是进程的虚拟地址空间中的一个同质区间，即有相同特性的连续地址范围(比如访问权限)。内核使用vm_area_struct结构管理一个独立的虚拟内存区域，包含起始终止地址、VMA标志、所属内存描述符等相关信息。每个VMA对mm_struct而言是唯一的，两个独立进程将同一个文件映射到各自地址空间，它们分别有一个vm_area_struct来标志自己的内存区域。两个线程共享一个地址空间，也共享所有的vm_area_struct结构体。
VMA标志：VM_SHARD表示内存区域映射是一个共享映射而非私有映射

* 创建地址区域 mmap() do_mmap()(内存映射区):
do_mmap():
1、将一个新的虚拟地址区间加入到进程的地址空间中，无论是扩展已有的VMA还是创建新的VMA。如果创建新的VMA，添加到地址空间的虚拟内存区域的链表和红黑树中，返回新分配区间的初始地址。(文件映射/匿名 映射)
2、文件映射时，调用驱动的mmap。通过文件的inode定位到文件磁盘物理地址，建立页表，实现用户空间的VMA和驱动空间物理地址的映射关系。但是，这片虚拟地址没有任何数据关联到内存中。
3.进程对这片映射空间访问，引发缺页异常，实现文件内容到物理内存的拷贝。进程读或写这一段映射地址时，查询页表发现只建立了地址映射，页面不在物理页面上，引发缺页异常。内核调页，进程对这片内存进行读写。如果写操作改变了内容，一段时间后系统会将脏页自动写回硬盘，也可以使用mysnc()来强制同步。

mmap2():用户空间通过mmap2()系统调用获取内核函数do_mmap()的功能。 
munmap() do_munmap() 删除地址区间

进程内存分配回收： 
Fork execve mmap等进程控制原语涉及进程的内存分配。不过这时进程获得的是虚拟内存，内核调用了do_mmap()。然后当进程访问新获取的虚拟地址时，才会由“请求页机制”产生“缺页”异常，从而进入分配实际页面的例程。（分配物理页，建立对应页表项）

MMU，全称内存管理单元。功能是把虚拟地址转换为物理地址。
TLB就是页表的Cache，其中存储了当前最可能被访问到的页表项，其内容是部分页表项的一个副本。只有在TLB无法完成地址翻译任务时，才会到内存中查询页表。CPU会首先根据虚拟地址的高20位（20是x86特定的，不同架构有不同的值）在TLB中查找。如果是表中没有相应的表项，称为TLB miss，需要通过访问慢速RAM中的页表计算出相应的物理地址。同时，物理地址被存放在一个TLB表项中，以后对同一线性地址的访问，直接从TLB表项中获取物理地址即可，称为TLB hit。
使用页表，多级页表，需要多次内存访问。
linux使用三级页表，完成虚拟地址到物理地址的转换，TLB快表作为转换的硬件缓存。
每个进程的mm_struct 都有指针指向自己的PGD(页全局目录)

TLB 
cpu需要快速判断页表项是否在TLB内，在TLB的哪个条目内。
TLBcache 中表项和虚拟地址的关系：
全连接：一个TLB表项可以和任意线性虚拟地址的页表项关联(空间利用最好/查找需要逐一比较，效率低)
直接匹配：每一个虚拟地址块都可通过模运算对应到唯一的TLB表项(发生冲突/查找快，空间利用不好)
组相连：把所有的TLB表项分成多个组，每个线性地址块对应的不再是一个TLB表项，而是一个TLB表项组。按照组长度，我们可以称之为2路，4路，8路。

cache：高速缓冲存储器。L1cache，L2cache，L3cache。速度越来越慢，每字节成本越来越低，容量越来越大。作用是为了更好的利用局部性原理，减少CPU访问主存的次数。cache的容量要远远小于主存，主存地址和cache的映射关系有3种：全连接/直接匹配/组连接。一般使用组连接，通常为8路组连接。一个cache被分为若干个组，一个组的长度为8个cache line。一个cacheline有若干个Byte。当从内存中取数据单元到cache中时，会一次取一个cacheline大小的内存区域到cache中，然后存进相应的cacheline中。linesize是cache的基本单位，从主存向cache迁移数据都是按照linesize为单位替换的。

brk():
mm_struct中,start_brk是进程动态分配的起始地址（堆的起始地址），brk 是堆当前最后的地址。　　　　　　
sbrk()是库函数，brk()是系统调用。都是改变brk的值来扩展收缩堆（increment 为负数时收缩）。

缺页异常：
ps命令查看进程缺页中断次数。
发生缺页异常中断，进程陷入内核态：
1、检查要访问的虚拟地址是否合法
2、查找分配物理页
3、填充物理页内容(读取磁盘/置0)
4、刷新页表，建立映射关系。
重新执行发生缺页中断的指令。

64位操作系统：
1、虚拟地址只使用48位，高的16位，在用户地址空间中置0，在内核地址空间中置1。线性地址48位，可管理256T的空间，在32位系统模式下，只能管理4G。虚拟线性地址到物理地址的转换使用4级页表来完成（位宽分别9、9、9、9、页内偏移12）。
2、用户空间和内核空间各128T，由于前面16位的变化，用户空间和内核空间之间存在一个巨大的空洞。(虚拟地址空间不连续)，可以用于以后的扩展。
3、64位系统的最大物理内存为64T，在128T内核空间中，低的64T用于直接和物理空间进行映射(区别于32位系统中，使用高端内存的方法，由于地址空间的限制，内核只会将0~896M的地址进行映射)，32T用于vmalloc/ioremap。

ioremap(通常只实现一个物理地址空间，外设I/O端口成为内存的一部分。此时，CPU可以象访问一个内存单元那样访问外设I/O端口，而不需要设立专门的外设I/O指令。一般来说，在系统运行时，外设的I/O内存资源的物理地址是已知的，由硬件的设计决定。但是CPU通常并没有为这些已知的外设I/O内存资源的物理地址预定义虚拟地址范围，驱动程序并不能直接通过物理地址访问I/O内存资源，而必须将它们映射到内核虚地址空间内(通过页表)，然后才能根据映射所得到的内核虚地址范围，通过访内指令访问这些I/O内存资源。)

mmap和ioremap
1、mmap()函数是用来将设备内存线性地址映射到用户地址空间
2、ioremap()函数是用来将物理地址映射到内核的虚拟地址。

为什么不把所有的地址空间都分配给内核？
若把所有地址空间都给内存，那么用户进程怎么使用内存。
没有机制保证内核使用内存和用户进程不起冲突，内核态和用户态的数据交互也是问题。

* 现在进程通过系统调用进入了内核，在系统空间中运行，内核代表进程执行，并处于进程上下文中。MMU根据进程task_struct中的页全局目录PGD完成虚拟地址到物理地址的映射，系统调用时往往需要从用户空间到系统空间数据的复制copy_from_user()，或者系统空间对用户空间有数据的写入copy_to_user()。从用户态进入内核态，cpu需要进行堆栈的切换，进程用户栈切换到内核栈，但进程上下文不变，页全局目录PGD不变（唯一的）。(如果内核与进程都是完全独立的虚拟地址空间，那么进程陷入内核没有办法完成内核空间与用户空间的数据交互)

linux使用了简化的分段机制：内核代码段、数据段，用户代码段、数据段的段首基地址都是0，虚拟地址=线性地址。但是分段实现了权限控制，将每个段设置权限位，让不同的程序访问不同的段。内核代码段和内核数据段都需要CPL(cpu特权级，0最高内核态使用，3最低，用户态使用)为0时才能访问，而用户代码段和用户数据段在CPL为0或者3时都可以访问。陷入内核后获取对应段选择符(一般都是__KERNEL_CS)，进行特权级检查后放入CS寄存器中。根据段选择符在内核的全局描述符表（GDT）或LDT中找到段描述符，根据段描述符里面的段基址以及虚拟地址的偏移量就能够寻址3G-4G的内核地址。


虚拟内存：
它使得应用程序认为它拥有连续的可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。
1、可以弥补物理内存的不足。
2、进程的虚拟地址空间，相互之间有保护。

内存碎片：
1、固定式分区分配中存在内碎片，可变式分区分配中存在外碎片(分区大小动态变化，首先适配、最佳适配、最差适配、下一次适配)。
2、伙伴系统（有效解决外碎片）。

内核将页分为:
不可移动页：这些页在内存中有固定的位置，不能够移动。
可回收页：这些页不能移动，但可以删除。内核在回收页占据了太多的内存时或者内存短缺时进行页面回收。
可移动页：这些页可以任意移动，用户空间应用程序使用的页都属于该类别。它们是通过页表映射的。当它们移动到新的位置，页表项也会相应的更新。

进程内存空间怎么映射共享库：
1、程序运行时才链接共享库，通过mmap把磁盘的共享库文件映射到虚拟地址空间，程序真正访问时触发缺页异常，操作系统把共享库文件内容加载到内存。

2、多个进程映射一个共享库，进程退出时释放共享库，内存管理上是怎样的机制？共享库都没进程引用了会怎么办？
多个进程共用共享库，共享库在内存只有一份，有个引用计数，进程加载同个共享库时引用计数加1，进程释放共享库时引用计数减1，最后没有进程引用时引用计数为0，操作系统卸载共享库，释放内存。


### ptmalloc
malloc/free
ptmalloc是glibc默认的内存管理器。我们常用的malloc和free就是由ptmalloc内存管理器提供的基础内存分配函数。
通过chunk的数据结构来组织每个内存单元。空闲的chunk会被放置到空闲区链表bins。用户使用free函数释放掉的内存，ptmalloc并不会马上交还给操作系统，而是被ptmalloc本身的空闲链表bins管理起来了，这样当下次进程需要malloc一块内存的时候，ptmalloc就会从空闲的bins上寻找一块合适大小的内存块分配给用户使用。这样的好处可以避免频繁的系统调用，降低内存分配的开销和内存碎片的产生。

1、为了解决多线程锁争夺问题，分为主分配区main_area和非主分配区no_main_area。
2、每个进程有一个主分配区，也可以允许有多个非主分配区。
3、使用malloc分配时需要获取对应分配区的锁，防止race condition，然后在空闲链表bins中寻找合适的内存块，找不到时，再分配内存。如果主分区上，分配的内存小于128k，则使用brk()分配一块内存；如果分配的内存大于128K，则需要mmap来分配；非主分区上，则直接使用mmap来分配一块内存
mm_struct中,start_brk是进程动态分配的起始地址（堆的起始地址），brk是堆当前最后的地址。　　　　　　
sbrk()是库函数，brk()是系统调用。都是改变brk的值来扩展收缩堆（increment 为负数时收缩）。
mmap()->do_mmap() / brk()


free：
1、获取对应分配区的锁
2、如果当前chunk是mmap映射区映射的内存，使用munmap释放掉这块内存。
3、放入bins空闲链表中

brk分配的内存需要等到高地址内存释放以后才能释放，而mmap分配的内存可以单独释放。

brk分配堆内存在虚拟内存空间上是连续的，高地址内存释放了，低地址内存才能释放，如果大内存用brk，那么就很容易产生大的内存碎片。
mmap的分配效率低，每次munmap的时候都需要释放内存，如果小内存的话，相比可以重用小内存的brk而言，其缺页中断次数会激增，导致程度性能下降。

### Linux物理内存管理：(物理内存使用伙伴系统管理)
内核把物理页作为内存管理的基本单位，32位系统的页4KB,64位系统的页8KB。内核用struct page表示物理页(_count存放页引用计数/flags存放页的状态/void*virtual是页的虚拟地址)使用伙伴系统来管理空闲物理页面。伙伴系统将所有空闲页框分组为11个块链表(空闲页链表数组free_area[MAX_ORDER])。每个块链表分别包含大小为：1，2，4，8，16，……1024个连续页框的页框块。假如需要4个页面大小的页框块，就到free_area[2]中查找，如果链表中有空闲块，就从链表中摘下分配出去。如果没有，顺着free_area数组向上查找free_area[3],如果有空闲块，将该空闲块分成相等两块，也就是伙伴(大小相同/地址连续/从一个大块中分离出的两块)。一块分配出去，一块放入free_area[2]。释放时，如果有伙伴块则要合并并考察下一级链表，直到不能合并或者已经成为最大的块为止，插入对应链表头部。

* 内核使用区对相似特性的页进行分组(struct zone)：
ZONE_DMA 这个分区的页用来执行DMA操作
ZONE_NORMAL 可以正常映射的页
ZONE_HIGHMEM：32位系统的高端内存区。不能永久映射到内核地址空间

* 分配页：
alloc_page/alloc_pages 分配1/2^order页，返回指向第一页页结构指针
_get_free_page/_get_free_pages 分配1/2^order页，返回指向第一页逻辑地址的指针。
释放页：
_free_pages  free_page/free_pages

* kmalloc/kfree:获得以字节为单位的一块内存

* vmalloc/vfree:
void* vmalloc(uint long size)
分配连续的虚拟地址，但是实际的物理地址不连续。大多数情况下，只有硬件设备要连续的物理地址的内存。
vmalloc为了把物理地址不连续的页转化为虚拟地址空间上连续的页，必须建立页表项，并且通过vmalloc获得的页必须一个个映射，会导致比直接内存映射大的多的TLB抖动。所以vmalloc一般用于获取大块内存。

slab分配器：
缓存频繁使用的数据结构。1、防止频繁分配和释放的开销 2、带来的内存碎片。
slab层把不同的缓存对象分成不同的高速缓存组，每个高速缓存组划分成slab(1个或多个连续物理页，一般一页)
空页/半满页/满页 
高速缓存用kmem_cache结构表示，包含三个链表：slabs_full、slabs_partial、slabs_empty。
当没有可用页时，通过_get_free_pages获取新的页

kmem_cache_create(按高速缓存行对齐，防止伪共享)/kmem_cache_destroy
kmem_cache_alloc/kmem_cache_free

内核栈：内核为每个进程分配的内核栈是两页，32/64系统的内核栈大小分别位8/16KB。中断处理程序使用它们所中断的进程的内核栈。编译时可配置进程内核栈大小为1页，这时中断处理程序不在和被中断进程共享内核栈，而使用单独的中断栈。

* 分段机制：
1、将物理内存划分为多个段，让操作系统可以使用大于其地址线寻址的物理内存(比如正常情况下32位地址线可以访问4G大小的内存，但是有分段后则可访问大于4G的内存)。
2、权限控制，将每个段设置权限位，让不同的程序访问不同的段。

寄存器中保存：段选择符(索引号，在GDT或LDT中的索引，TI表指示器，指示对应段描述符在GDT或是LDT中)
段描述符：保存于全局描述符表(GDT)地址和大小保存GDTR寄存器中 局部描述符表(LDT) 地址和大小被保存在LDTR中。

cs代码段寄存器
ds数据段寄存器：静态数据段和全局数据段
ss栈段寄存器

32位系统逻辑地址是由段选择符(16位) + 段内偏移量offset(32位)得来。由段选择符在GDT或LDT中找到对应段描述符，得到段首基地址加上offset偏移地址得到线性地址。
内核代码段、数据段，用户代码段、数据段的段首基地址都是0x00000000。但是内核代码段和内核数据段都需要CPL(cpu特权级，0最高内核态使用，3最低，用户态使用)为0时才能访问，而用户代码段和用户数据段在CPL为0或者3时都可以访问。实际上的逻辑地址=线性地址，也就是offset。

从用户态陷入内核态，地址映射转换是怎么做的？
1、如果是中断会读取由idtr寄存器保存的IDT(中断向量表)中对应的门描述符(中断向量)。2、根据对应的门描述符，获取其中保存的段选择符(一般都是__KERNEL_CS)，进行特权级检查后放入CS寄存器中。
3、根据段选择符在内核的全局描述符表（GDT）或LDT中找到段描述符，根据段描述符里面的段基址以及虚拟地址的偏移量就能够寻址3G-4G的内核地址
而内核栈中保存的值有：用户态CS，用户态SS，用户态ESP，用户态EIP，用户态eflags。当系统从中断返回用户态时，就会从内核栈中将这些值还原，最后会回到进入时的情况

x86的中断处理过程？中断现场怎么保存？
中断向量表，内核栈（中断栈）

IDTR寄存器中保存IDT(中断描述符表)的起始地址和大小,IDT中每一项称为一个中断门或者陷阱门，根据中断向量的中断描述符找到对应的中断门，基于这个中断门可以进一步获得这个中断门相关的段选择符和偏移地址。根据段选择符在GDT或LDT中找到对应段描述符，根据段描述符的基地址和中断门的偏移地址，找到目标代码段的线性地址。也就是中断服务例程。

* 系统调用：
1、通知内核的机制通过软中断实现：引发异常促使系统切换到内核态去执行异常处理程序(系统调用处理程序)。x86上预定义的软中断号128，通过int$0x80指令触发该中断。这个系统调用才处理程序就是system_call()。系统调用号通过eax寄存器传递给内核。

2、内核向用户空间写入数据copy_to_user()和内核从用户空间中读数据copy_from_user()

3、系统调用上下文：内核在执行系统调用的时候处于进程上下文。

### linux进程/线程
进程也叫task，task_struct称为进程描述符，存放在task_list双向链表中(任务队列)。task_struct通过slab分配器分配来达到对象复用目的。进程内核栈尾端创建一个struct thread_info，结构中task字段指向对应task_struct。内核通过current宏查找正在运行进程的进程描述符。

进程家族树：所有进程都是pid为1的init进程的后代。task_struct中，parent指针指向父进程，children指针指向子进程链表。

linux系统启动过程：
进程创建：fork() exec()读取可执行文件并将其载入到地址空间开始运行。
Linux fork(): 采用copy_on_write父子进程共享一个拷贝，只有在写入数据时拷贝被复制，从而各个进程拥有自己的拷贝(fork后立刻exec就不需要复制了)。fork的实际开销就是复制父进程页表，及给子进程创建唯一的进程描述符。
fork()->clone()->do_fork()
内核有意让子进程先执行，子进程一般exec，这样父进程就不用写时复制的开销了。但是未必能如愿。
vfork() 不拷贝父进程页表
子进程作为父进程的一个单独线程在它地址空间里运行，不能写入。父进程阻塞直到子进程exec或退出。

线程对于其他系统而言，是一种耗费资源较少、运行速度较快的执行单元，对linux而言，只是进程间共享资源的手段。调用clone()时传递一些标志表示资源的共享 VM/FS/FILES(打开文件) SIGHAND(信号处理程序)

内核进程没有独立地址空间，task_struct的mm域为空。

进程退出：进程exit()->do_exit()之后，进程通知父进程并变成僵尸进程，系统保留了它的task_struct，这样让系统在子进程终结后仍能获得它的信息。在父进程获得已终结子进程的信息后/或通知内核他不关注这些信息，子进程task_struct才被释放。通过wait()函数->wait4()系统调用。

孤儿进程：寻找养父，父进程退出时，寻找进程组内的其他进程或init进程作为它子进程的养父。

僵尸进程的解决：
1、父进程调用wait/waitpid获取终结子进程的信息。wait/waitpid会阻塞父进程，可以设置信号处理函数，子进程退出，父进程会收到sigchild信号，在信号处理函数中调用wait/waitpid
2、将子进程成为孤儿进程，从而其的父进程变为init进程，通过init进程可以处理僵尸进程。技巧是fork()两次，第一次fork的子进程退出，使第二次fork的子进程被init收养。防止第二次fork出的子进程成为僵尸进程。

### linux 进程调度
调度策略通常在响应时间和高吞吐量之间寻找平衡
进程优先级：1、nice值，越低优先级越高(友好值)2、实时优先级(越高实时优先级代表进程优先级越高)
cpu消耗性任务希望长时间片，高速缓存的命中率更高
IO消耗性任务希望短时间片，响应更快

完全公平调度CFS，是一个针对普通进程的调度类，SCHED_NORMAL
CFS在所有可运行进程总数基础上计算出一个进程该运行时间。CFS设定了一个理想的延迟调度周期称为目标延迟，进程不同的nice值获得不同的处理器运行时间比重而不是绝对值。(目标延迟20ms，2个相同nice值可执行任务每个获得10ms时间，CFS引入了每个进程获得的时间片的最小粒度，默认为1ms，以免可运行进程数量趋于无穷时每个任务获得时间片趋于0）

CFS使用红黑树组织可运行进程队列，节点的key为进程的虚拟运行时间vruntime，vruntime虚拟运行时间是进程的实际运行时间和进程获得处理器运行时间权重的比值计算出来的。CFS调度器选取最左侧的叶子节点，也就是虚拟运行时间最小的进程。

中断不能睡眠，中断上下文和current宏无关，和进程无关。没有办法被重新调度。

### 同步方法
多线程同步：
1、mutex 互斥锁对象 2、信号量 sem_get sem_op sem_ctl 3、条件变量 4、自旋锁 5、读写锁 6、seq锁 

原子性：指令在执行期不被打断，要么全部完成，要么全部不执行。一个数的读写是原子的。
顺序性：两条或多条指令，出现在独立的执行线程中，甚至独立处理器上，本该执行顺序依然保持

原子锁：atomic_t:volatile  lock前缀用来在执行被lock修饰的指令期间锁住总线
自旋锁：1、自旋锁不可长期持有，持有自旋锁不可睡眠2、禁止中断处理程序(中断处理程序如果争抢锁会死锁)

读写锁(读写自旋锁/读写睡眠锁)：1、锁倾向于读，写者要等到所有读者释放锁才能加锁，容易写饥饿。2、读加锁需要维护读者数，如果临界区小，不如使用普通的锁。3、为防止写饥饿，写加锁会阻塞后面的读加锁，因此追求低读延迟场合不适用。

信号量/mutex：睡眠锁，mutex限制更强，使用更简单，行为类似计数为1的信号量，不需要管理计数，信号量在非常底层才会使用。(计数为1/在同一上下文中加锁解锁/持有mutex进程不能退出)。睡眠锁不能在中断中使用，不需要禁止中断。

低开销上锁/短期上锁/中断上锁：自旋锁
长期加锁/持有锁需睡眠：mutex

顺序锁：seq锁，读写共享模型。多读者，少写者，写者优先级高(内核时间更新)。维护一个sequence，初始为0。
写者通过互斥锁防止写写冲突(写者很少)。开始写时sequence++，写完后sequence++。
读者读时seq为奇数等待，为偶数记录seq值开始读取记录。读完后检查记录seq值是否改变，改变则retry再次尝试读。
时钟读写如果使用普通读写锁，太多的gettimeofday会阻塞更新时间的中断处理程序。

顺序和屏障：X86不会对写重排，其他处理器读写重排，提高效率
rmb():读屏障 wmb():写屏障 mb()读/写屏障
提供读/写/读写屏障，保障跨越rmb/wmb/mb的载入/存储/载入和存储动作不会重排序。在屏障前的读/写操作不会被重新安排在该调用之后，屏障后的读写操作不会被重新安排在该调用之前。
编译器优化而产生的指令乱序，cpu指令流水线也会产生指令乱序，都是为了优化执行效率 
指令乱序：CPU一般采用流水线来执行指令，一个指令的执行被分成若干个阶段。指令流水线并不是串行的，而是并行的，多个指令可以同时处于同一个阶段(只有一个除法器除法指令需等待，而有两个加法器可以同时执行两条加法指令，位于除法指令后面的加法指令可能先被执行。两条访存指令，可能由于第二条指令命中了cache而导致它先于第一条指令完成。）

条件变量和信号量的区别：
条件变量本质上是一个等待队列，它支持阻塞等待和唤醒操作，可以将线程放入等待队列并将其状态设置为阻塞，然后从中获取线程并将其状态设置为就绪。注意，要使用条件变量，还需要另外两个元素：1、条件（通常通过检查标志或计数器实现2、保护条件的互斥锁
然后协议变成，1、获取互斥锁2、检查条件3、如果条件为真，则阻塞并释放互斥，否则释放互斥

信号量本质上是一个计数器+一个互斥锁+一个等待队列。它可以在没有外部依赖的情况下使用。可以将它用作互斥锁或条件变量。因此，信号量可以被视为比条件变量更复杂的结构，而条件变量则更轻量级、更灵活。

条件变量可以用于实现屏障同步。屏障同步是指希望所有线程等待，直到每个线程都到达线程函数中的某个部分。可以通过一个静态变量来实现，该静态变量初值是线程总数。每个线程到达该屏障时减一，所有线程都睡眠直到静态变量变为0，最后一个到达屏障的线程将唤醒所有的线程。

信号量的而主要目的是提供一种进程间同步的方式；这些进程可能共享也可能不共享内存区。互斥锁和条件变量是作为线程间的同步机制说明的；这些线程总是共享(某个)内存区。(条件变量的条件可以在共享内存区中，而信号量的不依赖外部，对象全部在内核中，更适合进程间同步)


### Linux的文件系统
用户打开文件表：files_struct
由进程描述符中的files目录项指向。所有与单个进程相关的信息(如打开的文件及文件描述符)保存在其中。持有打开的文件描述符记录open_fds，和文件对象数组 struct file* fd_array[NR_OPEN_DEFAULT](默认大小32或64)，(struct file ** fd指向文件对象的指针数组(一般指向fd_array,超过32后，内核分配新的空间给fd))。使用文件描述符作为下标，在fd指针数组中索引，可以找到相应的文件对象(file)指针。使用dup等命令，多个文件描述符指向同一个文件对象，即fd_array的多个元素有相同值。

系统打开文件表：open_file_description：file对象
内核使用一个双向链表来串联file对象，被称为系统打开文件表，由内核维护。文件对象表示进程已打开文件，多个进程可以同时打开和操作同一个文件，所以同一个文件可以存在多个文件对象
file对象：文件对象链表/文件对象的使用计数(多少文件描述符共享这个文件对象)/文件偏移量/f_dentry 指向对应的目录项对象  file_operations 封装了允许的操作。
元数据：
dentry: 目录项对象(路径中的每一个部分，包括普通文件都是目录项对象)：dcount 统计被多少个file对象引用。唯一的对应一个打开的文件。Inode* dinode指向关联的索引节点（快速解析路径，使用hash表组织了dentry节点，对路径计算hash值）
inode:索引节点，包含内核在操作文件或目录的所有信息。
Super_block: 超级块对象，用于存储特定文件系统的信息

fs_struct： 进程描述符的fs域指向fs_struct，它包含文件系统和进程相关的信息。root/pwd 两个字段 指向了了进程根目录和当前工作目录
 
### linux的数据结构
标准链表：环形双向链表
自定义结构体中内嵌struct list_head(包含prev/next字段)组成链表。结构体中变量的偏移地址时编译期确定的。使用宏命令container_of获取父结构type中包含的任意变量member。container_of(ptr,type,member)
遍历元素：list_for_each宏

队列：kfifo 维护一个入口偏移和一个出口偏移。出口偏移<=入口偏移。

映射idr：映射一个唯一标识数UID到一个指针。比如将定时器的id映射到内核关联的数据结构体上。
使用trie树+位图：建立32叉trie树，每个树节点有32位的位图标志每个分支是否有分配子节点。分级索引，每一级使用UID中的5位，使UID最终找到存储的ptr。比使用数组能更好利用内存，比使用链表检索的效率更高。

Unix有五种I/O 模型： 
阻塞式 I/O 应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回
非阻塞式I/O 
I/O 复用（select 和 poll） 
信号驱动式 I/O（SIGIO）  sigaction系统调用注册SIGIO的信号处理程序，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送SIGIO信号，应用进程收到之后在信号处理程序中将数据从内核复制到进程buffer。
异步 I/O（AIO）异步I/O与信号驱动I/O的区别在于，异步I/O的信号是通知应用进程I/O完成，而信号驱动I/O的信号是通知应用进程可以开始 I/O。



